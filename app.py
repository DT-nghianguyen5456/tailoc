import streamlit as st
import cv2
import numpy as np
import pytesseract
import re

# ==========================================
# C·∫§U H√åNH & H√ÄM PH·ª§ TR·ª¢
# ==========================================

def clean_text(text):
    """
    Ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i v√† s·ªë, lo·∫°i b·ªè nhi·ªÖu ƒë·∫∑c bi·ªát.
    Chuy·ªÉn ƒë·ªïi c√°c k√Ω t·ª± d·ªÖ nh·∫ßm l·∫´n.
    """
    # Thay th·∫ø c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát th∆∞·ªùng b·ªã nh·∫≠n nh·∫ßm tr∆∞·ªõc khi x√≥a
    text = text.replace('|', 'I').replace('l', 'I') 
    
    # Ch·ªâ gi·ªØ A-Z v√† 0-9
    clean = re.sub(r'[^a-zA-Z0-9]', '', text).upper()
    return clean

def sort_contours_grid(cnts, row_sensitivity=15):
    """S·∫Øp x·∫øp contour theo l∆∞·ªõi (Tr√°i->Ph·∫£i, Tr√™n->D∆∞·ªõi)"""
    boundingBoxes = [cv2.boundingRect(c) for c in cnts]
    c_boxes = list(zip(cnts, boundingBoxes))
    
    # S·∫Øp x·∫øp theo Y tr∆∞·ªõc (ƒë·ªÉ chia d√≤ng)
    c_boxes.sort(key=lambda b: b[1][1]) 

    rows = []
    current_row = []
    last_y = -999

    for c, box in c_boxes:
        y = box[1]
        h = box[3]
        # N·∫øu box n√†y n·∫±m c√πng d√≤ng v·ªõi box tr∆∞·ªõc (ch√™nh l·ªách y kh√¥ng qu√° l·ªõn)
        if y - last_y < row_sensitivity and last_y != -999:
            current_row.append((c, box))
        else:
            if current_row:
                # D√≤ng c≈© ƒë√£ xong, s·∫Øp x·∫øp d√≤ng c≈© theo X (Tr√°i -> Ph·∫£i)
                current_row.sort(key=lambda b: b[1][0])
                rows.extend(current_row)
            # B·∫Øt ƒë·∫ßu d√≤ng m·ªõi
            current_row = [(c, box)]
            last_y = y
    
    # Th√™m d√≤ng cu·ªëi c√πng
    if current_row:
        current_row.sort(key=lambda b: b[1][0])
        rows.extend(current_row)

    return [item[0] for item in rows]

def preprocess_roi_for_ocr(roi):
    """
    Chu·∫©n b·ªã ·∫£nh c·∫Øt (ROI) ƒë·ªÉ OCR t·ªët nh·∫•t:
    1. Ph√≥ng to (Upscale).
    2. Chuy·ªÉn x√°m & Nh·ªã ph√¢n h√≥a (Threshold).
    3. Th√™m vi·ªÅn tr·∫Øng (Padding).
    """
    # 1. Ph√≥ng to ·∫£nh l√™n 3 l·∫ßn (Gi√∫p Tesseract ƒë·ªçc ch·ªØ nh·ªè t·ªët h∆°n)
    roi = cv2.resize(roi, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)
    
    # 2. Threshold OTSU ƒë·ªÉ t√°ch ch·ªØ ƒëen tr√™n n·ªÅn tr·∫Øng
    # L∆∞u √Ω: Code trong ·∫£nh l√† ch·ªØ ƒëen n·ªÅn tr·∫Øng -> Binary th∆∞·ªùng (kh√¥ng INV) ho·∫∑c INV t√πy theo background
    # ·ªû ƒë√¢y d√πng THRESH_BINARY v√¨ text m√†u ƒëen, n·ªÅn tr·∫Øng, sau threshold text s·∫Ω l√† ƒëen (0) n·ªÅn tr·∫Øng (255)
    # Tesseract th√≠ch ch·ªØ ƒëen n·ªÅn tr·∫Øng ho·∫∑c ng∆∞·ª£c l·∫°i ƒë·ªÅu ƒë∆∞·ª£c, nh∆∞ng chu·∫©n nh·∫•t l√† ch·ªØ ƒëen n·ªÅn tr·∫Øng.
    _, thresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # 3. Th√™m vi·ªÅn tr·∫Øng xung quanh ƒë·ªÉ ch·ªØ kh√¥ng b·ªã s√°t m√©p
    thresh = cv2.copyMakeBorder(thresh, 20, 20, 20, 20, cv2.BORDER_CONSTANT, value=255)
    
    return thresh

def process_image(image_file):
    # ƒê·ªçc ·∫£nh
    file_bytes = np.asarray(bytearray(image_file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)
    
    # X·ª≠ l√Ω t√¨m khung Button
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # D√πng HSV ƒë·ªÉ b·∫Øt m√†u tr·∫Øng (n·ªÅn button)
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower_white = np.array([0, 0, 180]) 
    upper_white = np.array([180, 50, 255])
    mask = cv2.inRange(hsv, lower_white, upper_white)
    
    # Morph Open ƒë·ªÉ x√≥a nhi·ªÖu ch·ªØ, gi·ªØ l·∫°i kh·ªëi button
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15)) # TƒÉng kernel l√™n ch√∫t
    mask_clean = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    
    cnts, _ = cv2.findContours(mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    valid_contours = []
    img_h, img_w = img.shape[:2]

    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        area = w * h
        aspect_ratio = w / float(h)
        
        # L·ªçc khung code (H√¨nh ch·ªØ nh·∫≠t n·∫±m ngang)
        if area > 1000 and 2.0 < aspect_ratio < 7.0 and w < (img_w * 0.8):
            # Ki·ªÉm tra ƒë·ªô s√°ng trung b√¨nh ƒë·ªÉ lo·∫°i b·ªè c√°c box n·ªÅn t·ªëi (nh∆∞ Telegram)
            roi_check = gray[y:y+h, x:x+w]
            mean_val = cv2.mean(roi_check)[0]
            if mean_val > 160: # N·ªÅn s√°ng
                valid_contours.append(c)

    detected_codes = []
    
    if valid_contours:
        # S·∫Øp x·∫øp contour theo l∆∞·ªõi
        valid_contours = sort_contours_grid(valid_contours, row_sensitivity=25)
        
        for idx, c in enumerate(valid_contours):
            x, y, w, h = cv2.boundingRect(c)
            
            # Crop v√πng ·∫£nh (Padding v√†o trong m·ªôt ch√∫t ƒë·ªÉ b·ªè vi·ªÅn button)
            pad_y = int(h * 0.15) # B·ªè 15% tr√™n d∆∞·ªõi
            pad_x = int(w * 0.05) # B·ªè 5% tr√°i ph·∫£i
            
            roi = gray[y+pad_y : y+h-pad_y, x+pad_x : x+w-pad_x]
            
            if roi.size == 0: continue
            
            try:
                # --- X·ª¨ L√ù ·∫¢NH TR∆Ø·ªöC KHI OCR ---
                processed_roi = preprocess_roi_for_ocr(roi)
                
                # C·∫•u h√¨nh Tesseract: 
                # --psm 7: Treat the image as a single text line.
                # B·ªè whitelist c·ª©ng ƒë·ªÉ n√≥ ƒë·ªçc t·ª± nhi√™n, sau ƒë√≥ m√¨nh clean b·∫±ng Python
                config = r'--psm 7'
                
                text = pytesseract.image_to_string(processed_roi, config=config)
                
                # L·ªçc s·∫°ch text
                final_code = clean_text(text)
                
                if len(final_code) >= 4: # Ch·ªâ l·∫•y n·∫øu ƒë·ªô d√†i >= 4 k√Ω t·ª±
                    detected_codes.append(final_code)
                    
                    # V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh
                    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    # V·∫Ω n·ªÅn ƒëen cho ch·ªØ d·ªÖ ƒë·ªçc
                    cv2.rectangle(img, (x, y+h-25), (x+w, y+h), (0,0,0), -1)
                    cv2.putText(img, final_code, (x + 10, y + h - 5), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            except Exception as e:
                print(f"Error processing box {idx}: {e}")
                continue

    return img, detected_codes, mask_clean

# --- GIAO DI·ªÜN STREAMLIT ---
st.set_page_config(page_title="Tool Scan Code OKVIP", layout="wide")
st.title("üß© Tool Qu√©t Code - Optimized")
st.markdown("ƒê√£ t·ªëi ∆∞u: **Upscale ·∫£nh** + **T·∫Øt v·∫Ω l·∫°i contour** + **L·ªçc nhi·ªÖu Regex**")

uploaded_file = st.file_uploader("T·∫£i ·∫£nh l√™n...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    col1, col2 = st.columns([2, 1])
    
    processed_img, codes, debug_mask = process_image(uploaded_file)
    
    with col1:
        st.subheader("·∫¢nh ƒë√£ x·ª≠ l√Ω")
        st.image(cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB), use_container_width=True)
        
    with col2:
        st.subheader("K·∫øt qu·∫£ Code")
        if codes:
            # Join with newline
            txt = "\n".join(codes)
            st.text_area("Copy t·∫°i ƒë√¢y:", value=txt, height=500)
            st.success(f"T√¨m th·∫•y {len(codes)} m√£.")
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y m√£ n√†o ho·∫∑c ·∫£nh qu√° m·ªù.")
